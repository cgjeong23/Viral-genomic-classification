{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pLT-kTPRw2a7","outputId":"6e7c9e1a-174e-4035-f5fb-4831ac93c306"},"outputs":[],"source":["!pip install tokenizers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OsAs362r7Gzq","outputId":"6df76396-0179-4b52-eb06-f18a2a7e31c8"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-giXsqCTNVq-","outputId":"806545e2-d6c7-4698-ae07-1a8d5ad3825e"},"outputs":[],"source":["!git clone https://github.com/cgjeong23/Viral-genomic-classification.git virus"]},{"cell_type":"markdown","metadata":{"id":"L0ziw01lNU9t"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHVuLYHONU9u"},"outputs":[],"source":["from virus.ML.model import SkipGramEmbeddingModel\n","from virus.ML.train import train, evaluate\n","from virus.ML.dataloader import load_sequences, sample_data, get_3_splits, SequenceDataset\n","from torch import nn\n","from torch.utils.data import DataLoader\n","\n","import numpy as np\n","import os\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"XrCrHVRv4Nuz"},"source":["# Do Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["use_google_drive = False\n","use_kaggle = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndB83Lk_8-du"},"outputs":[],"source":["google_drive_path = '/content/drive/MyDrive'\n","\n","if use_google_drive:\n","    base_path = f'{google_drive_path}/trainingdata'\n","    tokenizer_file = f'{google_drive_path}/gene_tokenizer.json' \n","elif use_kaggle:\n","    base_path = '../input/pacific-sra/trainingdata'\n","    tokenizer_file = '../input/pacific-sra/gene_tokenizer.json'\n","else:\n","    base_path = 'trainingdata'\n","    tokenizer_file = 'gene_tokenizer.json'\n","\n","sequences, labels = load_sequences(base_path, train_embedding=True)\n","\n","(train_seq, valid_seq, test_seq,\n"," train_label, valid_label, test_label) = get_3_splits(sequences, labels)\n","\n","label_dict = {k: i for i, k in enumerate(np.unique(labels))}\n","\n","train_dataset = SequenceDataset(train_seq, train_label, tokenizer_file=tokenizer_file,\n","                                label_dict=label_dict)\n","valid_dataset = SequenceDataset(valid_seq, valid_label, tokenizer_file=tokenizer_file,\n","                                label_dict=label_dict)\n","test_dataset = SequenceDataset(test_seq, test_label, tokenizer_file=tokenizer_file,\n","                               label_dict=label_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CwT_tWpX5czF"},"outputs":[],"source":["lr = 1e-2\n","batch_size = 5000\n","num_epochs = 1\n","vocab_size = train_dataset.tokenizer.get_vocab_size()\n","pad_id = train_dataset.tokenizer.padding['pad_id']\n","embedding_dim = 256\n","window_size = 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ilx5kkj74d1h"},"outputs":[],"source":["import torch\n","model = SkipGramEmbeddingModel(vocab_size, embedding_dim, pad_id, window_size)\n","model = model.to('cuda')\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate_fn)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=valid_dataset.collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=test_dataset.collate_fn)\n","loss_function = nn.CrossEntropyLoss(ignore_index=pad_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IV9nHKxT4PPy"},"outputs":[],"source":["kaggle_path = '/kaggle/working'\n","\n","if use_kaggle:\n","    save_path = kaggle_path\n","elif use_google_drive:\n","    save_path = google_drive_path\n","else:\n","    save_path = '.'\n","\n","loss_history = train(model, train_loader, loss_function, lr, num_epochs, \n","                    valid_loader=valid_loader, test_loader=test_loader, train_skip_gram=True,\n","                    base_path=save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vx05lI43xmrb"},"outputs":[],"source":["loss_history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Or05uIYlySRY"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(loss_history['train'], label='train')\n","plt.plot(loss_history['valid'], label='valid')\n","plt.plot(loss_history['test'], label='test')\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eY2KcLoHye2c"},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"1242238a27090cfd0a9f95cca18072a5b0343382fab30269241b63569e4c53cd"},"kernelspec":{"display_name":"Python 3.9.12 64-bit ('datascience': conda)","name":"python3"},"language_info":{"name":"python","version":""}},"nbformat":4,"nbformat_minor":4}