{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install tokenizers","metadata":{"id":"pLT-kTPRw2a7","outputId":"6e7c9e1a-174e-4035-f5fb-4831ac93c306","execution":{"iopub.status.busy":"2022-08-04T07:19:05.573604Z","iopub.execute_input":"2022-08-04T07:19:05.574509Z","iopub.status.idle":"2022-08-04T07:19:05.600823Z","shell.execute_reply.started":"2022-08-04T07:19:05.573977Z","shell.execute_reply":"2022-08-04T07:19:05.599467Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/drive')","metadata":{"id":"OsAs362r7Gzq","outputId":"6df76396-0179-4b52-eb06-f18a2a7e31c8","execution":{"iopub.status.busy":"2022-08-04T07:19:05.649824Z","iopub.execute_input":"2022-08-04T07:19:05.650561Z","iopub.status.idle":"2022-08-04T07:19:05.655076Z","shell.execute_reply.started":"2022-08-04T07:19:05.650506Z","shell.execute_reply":"2022-08-04T07:19:05.653894Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/cgjeong23/Viral-genomic-classification.git virus","metadata":{"id":"-giXsqCTNVq-","outputId":"806545e2-d6c7-4698-ae07-1a8d5ad3825e","execution":{"iopub.status.busy":"2022-08-04T07:19:05.710607Z","iopub.execute_input":"2022-08-04T07:19:05.711295Z","iopub.status.idle":"2022-08-04T07:19:08.729482Z","shell.execute_reply.started":"2022-08-04T07:19:05.711258Z","shell.execute_reply":"2022-08-04T07:19:08.728157Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"L0ziw01lNU9t"}},{"cell_type":"code","source":"from virus.ML.model import RnnModel, RnnModelForClassification\nfrom virus.ML.train import train, evaluate\nfrom virus.ML.dataloader import load_sequences, sample_data, get_3_splits, SequenceDataset\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\nimport os\n\n%load_ext autoreload\n%autoreload 2","metadata":{"id":"lHVuLYHONU9u","execution":{"iopub.status.busy":"2022-08-04T07:19:08.733049Z","iopub.execute_input":"2022-08-04T07:19:08.733541Z","iopub.status.idle":"2022-08-04T07:19:11.481400Z","shell.execute_reply.started":"2022-08-04T07:19:08.733496Z","shell.execute_reply":"2022-08-04T07:19:11.480351Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Do Training","metadata":{"id":"XrCrHVRv4Nuz"}},{"cell_type":"code","source":"use_google_drive = False\nuse_kaggle = True","metadata":{"execution":{"iopub.status.busy":"2022-08-04T07:19:11.483064Z","iopub.execute_input":"2022-08-04T07:19:11.484073Z","iopub.status.idle":"2022-08-04T07:19:11.521436Z","shell.execute_reply.started":"2022-08-04T07:19:11.484033Z","shell.execute_reply":"2022-08-04T07:19:11.520236Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"google_drive_path = '/content/drive/MyDrive'\n\nif use_google_drive:\n    base_path = f'{google_drive_path}/trainingdata'\n    tokenizer_file = f'{google_drive_path}/gene_tokenizer.json' \nelif use_kaggle:\n    base_path = '../input/pacific-sra/trainingdata'\n    tokenizer_file = '../input/pacific-sra/gene_tokenizer.json'\nelse:\n    base_path = 'trainingdata'\n    tokenizer_file = 'gene_tokenizer.json'\n\nsequences, labels = load_sequences(base_path)\n\n(train_seq, valid_seq, test_seq,\n train_label, valid_label, test_label) = get_3_splits(sequences, labels)\n\nlabel_dict = {k: i for i, k in enumerate(np.unique(labels))}\n\ntrain_dataset = SequenceDataset(train_seq, train_label, tokenizer_file=tokenizer_file,\n                                label_dict=label_dict)\nvalid_dataset = SequenceDataset(valid_seq, valid_label, tokenizer_file=tokenizer_file,\n                                label_dict=label_dict)\ntest_dataset = SequenceDataset(test_seq, test_label, tokenizer_file=tokenizer_file,\n                               label_dict=label_dict)","metadata":{"id":"ndB83Lk_8-du","execution":{"iopub.status.busy":"2022-08-04T07:19:11.524335Z","iopub.execute_input":"2022-08-04T07:19:11.524735Z","iopub.status.idle":"2022-08-04T07:19:57.207923Z","shell.execute_reply.started":"2022-08-04T07:19:11.524697Z","shell.execute_reply":"2022-08-04T07:19:57.206719Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nclass_weight = compute_class_weight('balanced', classes=np.unique(train_label), y=train_label)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T07:19:57.209590Z","iopub.execute_input":"2022-08-04T07:19:57.210040Z","iopub.status.idle":"2022-08-04T07:20:06.231562Z","shell.execute_reply.started":"2022-08-04T07:19:57.209997Z","shell.execute_reply":"2022-08-04T07:20:06.230354Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\nCounter(labels)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T07:20:06.232925Z","iopub.execute_input":"2022-08-04T07:20:06.234805Z","iopub.status.idle":"2022-08-04T07:20:06.639920Z","shell.execute_reply.started":"2022-08-04T07:20:06.234748Z","shell.execute_reply":"2022-08-04T07:20:06.638338Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"lr = 1e-3\nbatch_size = 5000\nnum_epochs = 3\nvocab_size = train_dataset.tokenizer.get_vocab_size()\npad_id = train_dataset.tokenizer.padding['pad_id']\nembedding_dim = 256\nhidden_dim = 512\nnum_layers = 1\n\npretrained_emb_path = 'emb.pt'\nfreeze = True","metadata":{"id":"CwT_tWpX5czF","execution":{"iopub.status.busy":"2022-08-04T07:20:06.641964Z","iopub.execute_input":"2022-08-04T07:20:06.642875Z","iopub.status.idle":"2022-08-04T07:20:06.683360Z","shell.execute_reply.started":"2022-08-04T07:20:06.642831Z","shell.execute_reply":"2022-08-04T07:20:06.682145Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# load pretrained_embedding\nimport torch\nfrom virus.ML.model import SkipGramEmbeddingModel\n\nif pretrained_emb_path is not None and os.path.isfile(pretrained_emb_path):\n    emb_model = SkipGramEmbeddingModel(vocab_size, embedding_dim, pad_id, 2)\n    emb_model.load_state_dict(torch.load(pretrained_emb_path))\n    pretrained_emb = emb_model.embedding.weight\nelse:\n    print(f\"We could not load from {pretrained_emb_path}.\")\n    pretrained_emb = None","metadata":{"execution":{"iopub.status.busy":"2022-08-04T07:20:06.685254Z","iopub.execute_input":"2022-08-04T07:20:06.685664Z","iopub.status.idle":"2022-08-04T07:20:06.727147Z","shell.execute_reply.started":"2022-08-04T07:20:06.685625Z","shell.execute_reply":"2022-08-04T07:20:06.726102Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#model = RnnModel(vocab_size, embedding_dim, pad_id, hidden_dim, num_layers)\n\nmodel = RnnModelForClassification(vocab_size, embedding_dim, pad_id, hidden_dim, num_layers, \nlen(train_dataset.label_dict), pretrained_emb=pretrained_emb, freeze=freeze)\nmodel = model.to('cuda')\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate_fn)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=valid_dataset.collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=test_dataset.collate_fn)\nloss_function = nn.CrossEntropyLoss(weight=torch.Tensor(class_weight).to(\"cuda\"))","metadata":{"id":"ilx5kkj74d1h","execution":{"iopub.status.busy":"2022-08-04T07:20:06.728999Z","iopub.execute_input":"2022-08-04T07:20:06.729477Z","iopub.status.idle":"2022-08-04T07:20:11.361830Z","shell.execute_reply.started":"2022-08-04T07:20:06.729440Z","shell.execute_reply":"2022-08-04T07:20:11.360801Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"kaggle_path = '/kaggle/working'\n\nif use_kaggle:\n    save_path = kaggle_path\nelif use_google_drive:\n    save_path = google_drive_path\nelse:\n    save_path = '.'\n\nacc_history = train(model, train_loader, loss_function, lr, num_epochs, \n                    valid_loader=valid_loader, test_loader=test_loader,\n                    base_path=save_path)","metadata":{"id":"IV9nHKxT4PPy","execution":{"iopub.status.busy":"2022-08-04T07:20:11.364938Z","iopub.execute_input":"2022-08-04T07:20:11.365651Z","iopub.status.idle":"2022-08-04T08:24:58.495370Z","shell.execute_reply.started":"2022-08-04T07:20:11.365611Z","shell.execute_reply":"2022-08-04T08:24:58.493838Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"acc_history","metadata":{"id":"vx05lI43xmrb","execution":{"iopub.status.busy":"2022-08-04T08:24:58.497404Z","iopub.execute_input":"2022-08-04T08:24:58.497934Z","iopub.status.idle":"2022-08-04T08:24:58.562932Z","shell.execute_reply.started":"2022-08-04T08:24:58.497896Z","shell.execute_reply":"2022-08-04T08:24:58.561502Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(acc_history['train'], label='train')\nplt.plot(acc_history['valid'], label='valid')\nplt.plot(acc_history['test'], label='test')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()","metadata":{"id":"Or05uIYlySRY","execution":{"iopub.status.busy":"2022-08-04T08:24:58.565351Z","iopub.execute_input":"2022-08-04T08:24:58.565836Z","iopub.status.idle":"2022-08-04T08:24:58.932377Z","shell.execute_reply.started":"2022-08-04T08:24:58.565797Z","shell.execute_reply":"2022-08-04T08:24:58.931324Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"eY2KcLoHye2c"},"execution_count":null,"outputs":[]}]}